{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057857648\n",
      "0.010885106\n",
      "0.008560482\n",
      "0.0075904354\n",
      "0.0068486435\n",
      "0.006231291\n",
      "0.00568249\n",
      "0.0052411063\n",
      "0.0049438253\n",
      "0.0047059725\n",
      "0.004504467\n",
      "0.0043268185\n",
      "0.0041734898\n",
      "0.004053353\n",
      "0.0039504184\n",
      "0.003848823\n",
      "0.0037523597\n",
      "0.0036631743\n",
      "0.0035914094\n",
      "0.0035254788\n",
      "0.003451931\n",
      "0.0033879073\n",
      "0.0033356496\n",
      "0.003280852\n",
      "0.0032420743\n",
      "0.0032061993\n",
      "0.0031731634\n",
      "0.0031460486\n",
      "0.0031216445\n",
      "0.0030984718\n",
      "0.003077684\n",
      "0.003058212\n",
      "0.0030415864\n",
      "0.0030272233\n",
      "0.003014097\n",
      "0.0030017877\n",
      "0.0029899091\n",
      "0.0029781612\n",
      "0.0029676398\n",
      "0.0029579399\n",
      "0.002948619\n",
      "0.002939721\n",
      "0.002931438\n",
      "0.0029235668\n",
      "0.002916061\n",
      "0.0029082354\n",
      "0.0029003425\n",
      "0.0028924241\n",
      "0.0028847489\n",
      "0.0028772333\n",
      "0.0028700598\n",
      "0.0028634076\n",
      "0.0028571072\n",
      "0.0028512743\n",
      "0.002845651\n",
      "0.0028401257\n",
      "0.0028342206\n",
      "0.0028282544\n",
      "0.0028226844\n",
      "0.0028176892\n",
      "0.0028131735\n",
      "0.002808886\n",
      "0.0028048914\n",
      "0.0028010788\n",
      "0.002797395\n",
      "0.0027935116\n",
      "0.0027897467\n",
      "0.0027860487\n",
      "0.0027824747\n",
      "0.0027791294\n",
      "0.00277589\n",
      "0.0027728742\n",
      "0.0027699848\n",
      "0.0027671934\n",
      "0.0027644704\n",
      "0.0027618315\n",
      "0.002759278\n",
      "0.0027567968\n",
      "0.0027543465\n",
      "0.0027519984\n",
      "0.002749659\n",
      "0.0027473755\n",
      "0.0027452086\n",
      "0.002743316\n",
      "0.002741488\n",
      "0.002739712\n",
      "0.0027379938\n",
      "0.0027363286\n",
      "0.0027347147\n",
      "0.0027331482\n",
      "0.002731607\n",
      "0.002730101\n",
      "0.0027286364\n",
      "0.0027272138\n",
      "0.0027258333\n",
      "0.002724494\n",
      "0.0027232203\n",
      "0.0027220065\n",
      "0.0027208286\n",
      "0.002719679\n",
      "0.0027185786\n",
      "0.002717505\n",
      "0.0027164607\n",
      "0.002715446\n",
      "0.0027144593\n",
      "0.0027134973\n",
      "0.0027125576\n",
      "0.0027116444\n",
      "0.0027107522\n",
      "0.0027098828\n",
      "0.0027090327\n",
      "0.002708204\n",
      "0.0027073943\n",
      "0.002706604\n",
      "0.0027058346\n",
      "0.0027050797\n",
      "0.0027043459\n",
      "0.002703626\n",
      "0.0027029256\n",
      "0.0027022345\n",
      "0.0027015633\n",
      "0.0027009046\n",
      "0.002700257\n",
      "0.0026996227\n",
      "0.0026990045\n",
      "0.0026983982\n",
      "0.0026978015\n",
      "0.0026972163\n",
      "0.00269664\n",
      "0.0026960743\n",
      "0.00269552\n",
      "0.0026949735\n",
      "0.0026943646\n",
      "0.0026936037\n",
      "0.002692871\n",
      "0.0026921572\n",
      "0.002691453\n",
      "0.0026907634\n",
      "0.002690099\n",
      "0.002689528\n",
      "0.002688967\n",
      "0.002688414\n",
      "0.0026878687\n",
      "0.0026873285\n",
      "0.0026867974\n",
      "0.0026862742\n",
      "0.0026857522\n",
      "0.00268524\n",
      "0.0026847345\n",
      "0.002684232\n",
      "0.0026834696\n",
      "0.0026826304\n",
      "0.0026818186\n",
      "0.0026810272\n",
      "0.0026801499\n",
      "0.0026788942\n",
      "0.0026777026\n",
      "0.0026765757\n",
      "0.0026760176\n",
      "0.0026754895\n",
      "0.002674972\n",
      "0.002674464\n",
      "0.0026739633\n",
      "0.0026734853\n",
      "0.0026730201\n",
      "0.0026725687\n",
      "0.0026721174\n",
      "0.0026716746\n",
      "0.0026712397\n",
      "0.0026708061\n",
      "0.0026703798\n",
      "0.0026699563\n",
      "0.0026695377\n",
      "0.0026691111\n",
      "0.0026686855\n",
      "0.0026682622\n",
      "0.00266785\n",
      "0.0026674322\n",
      "0.0026670217\n",
      "0.0026666177\n",
      "0.002666208\n",
      "0.0026658059\n",
      "0.002665408\n",
      "0.0026650103\n",
      "0.0026646173\n",
      "0.0026642275\n",
      "0.0026638387\n",
      "0.0026634512\n",
      "0.0026630647\n",
      "0.0026626815\n",
      "0.0026623018\n",
      "0.002661923\n",
      "0.002661546\n",
      "0.0026611672\n",
      "0.0026607937\n",
      "0.002660421\n",
      "0.0026600466\n",
      "0.0026596761\n",
      "0.002659305\n",
      "0.002658936\n"
     ]
    }
   ],
   "source": [
    "#数据可视化\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#这一行是魔法命令行，很重要的\n",
    "%matplotlib qt5    \n",
    "#假如没有这一魔法命令行，就会显示不出这个拟合出来的曲线\n",
    "\n",
    "\n",
    "#这就是我们构建的一层神经网络，并返回这层神经网络的值\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs,Weights)+biases\n",
    "    \n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs          #这个输入层的是输出返回值是outputs\n",
    " \n",
    "#生成一些真实的数据，利用numpy\n",
    "x_data = np.linspace(-1,1,300)[:,np.newaxis]  #后面的中括号就是相当于加上他的维度，  意思就是一个特征有300个例子\n",
    "noise = np.random.normal(0,0.05,x_data.shape)   #利用numpy生成呈正态分布的误差，依次输入，均值，标准差，维度\n",
    "y_data = np.square(x_data)-0.5+noise            #需要拟合的曲线就是  x平方-0.5\n",
    "\n",
    "\n",
    "#定义placeholder为把数据传入神经网络做准备   这是不是相当于神经网络的第一层呢？？？\n",
    "xs = tf.placeholder(tf.float32,[None,1])   #这里的None是代表你输入多少个sample过来都可以，没有规定的意思\n",
    "ys = tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "#添加隐藏层          这一层的返回值是 l1 ，作为下一层的输入\n",
    "l1 = add_layer(xs,1,10,activation_function=tf.nn.relu)  #其实添加层的参数设置就是  \n",
    "                                                        #指出输入的数据，输入的维数，输出的维数，激励函数的指定\n",
    "\n",
    "#添加输出层         这一层的返回值是prediction \n",
    "prediction = add_layer(l1,10,1,activation_function=None)\n",
    "\n",
    "#构建代价函数，\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)  #括号中的0.1就是α学习率。andrew课堂中的\n",
    "                                                            #这个优化器的作用就是 使loss最小化，所以就是minimize\n",
    "\n",
    "\n",
    "#⭐⭐最最最重要的一步就是给全局的变量都要进行初始化\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#绘制出实体的数据,这一段就是绘制出你所提供的数据的散点图\n",
    "\n",
    "fig = plt.figure( )  #这就是先生成一个图片框\n",
    "ax = fig.add_subplot(1,1,1)  #这个是做连续性的画图\n",
    "ax.scatter(x_data,y_data)  #通过x_data与y_data来确定散点\n",
    "plt.ion()       #这一行的意思是   打开交互模式,可以连续输入多条线\n",
    "plt.show()      #显示这张图片\n",
    "\n",
    "\n",
    "#开始进行训练\n",
    "for i in range(10000):                #从0到999的循环\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})       #这一步就是开始训练的\n",
    "    if i % 50 == 0:            #每50次输出一次结果，查看训练效果     \n",
    "\n",
    "        try:                             #下面的步骤是为了显示整个训练过程中的可视化结果\n",
    "            ax.lines.remove(lines[0])   #抹除上一步拟合出来的曲线，使得每一次都只有一条拟合的线显示出来\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction,feed_dict={xs:x_data})\n",
    "        #画出整个的预测\n",
    "        lines = ax.plot(x_data,prediction_value,'r-',lw=5)\n",
    "        plt.pause(0.1)\n",
    "        print(sess.run(loss,feed_dict={xs:x_data,ys:y_data})) #只有里面有用到placeholder的地方，都要用回feed_dict才行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#添加神经层\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    biases = tf.Variable(tf.zeros(1,out_size)+0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs,Weights)+biases\n",
    "    \n",
    "    if activation_function == None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "#生成一些训练的数据\n",
    "x_data =\n",
    "noise = \n",
    "y_data = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
