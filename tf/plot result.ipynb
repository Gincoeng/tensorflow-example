{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48070067\n",
      "0.010716493\n",
      "0.0077328775\n",
      "0.006763537\n",
      "0.0060829734\n",
      "0.0056861457\n",
      "0.005390331\n",
      "0.0051211487\n",
      "0.0048412904\n",
      "0.0045655896\n",
      "0.004340716\n",
      "0.004160789\n",
      "0.004003372\n",
      "0.00385016\n",
      "0.0037121216\n",
      "0.0035978444\n",
      "0.003510135\n",
      "0.0034394045\n",
      "0.0033819417\n",
      "0.0033333034\n",
      "0.0032891666\n",
      "0.0032491162\n",
      "0.0032168385\n",
      "0.003183914\n",
      "0.0031562317\n",
      "0.0031323528\n",
      "0.0031102258\n",
      "0.0030897034\n",
      "0.0030719861\n",
      "0.003057105\n",
      "0.003044571\n",
      "0.0030335358\n",
      "0.0030213033\n",
      "0.003010081\n",
      "0.0030014464\n",
      "0.0029940153\n",
      "0.0029856216\n",
      "0.0029780464\n",
      "0.0029713681\n",
      "0.0029652454\n",
      "0.0029594924\n",
      "0.0029540446\n",
      "0.0029490653\n",
      "0.002944052\n",
      "0.0029391383\n",
      "0.00293444\n",
      "0.0029302593\n",
      "0.0029263198\n",
      "0.0029226865\n",
      "0.0029192166\n",
      "0.0029158932\n",
      "0.002912709\n",
      "0.0029097013\n",
      "0.0029068207\n",
      "0.0029040745\n",
      "0.0029014517\n",
      "0.002898935\n",
      "0.00289652\n",
      "0.0028941974\n",
      "0.002891963\n",
      "0.002889811\n",
      "0.0028877372\n",
      "0.0028857354\n",
      "0.0028838024\n",
      "0.0028817796\n",
      "0.0028797304\n",
      "0.002877884\n",
      "0.0028760901\n",
      "0.0028743974\n",
      "0.0028727404\n",
      "0.0028711194\n",
      "0.0028695907\n",
      "0.002868133\n",
      "0.0028667361\n",
      "0.0028653936\n",
      "0.002864101\n",
      "0.0028628542\n",
      "0.0028616523\n",
      "0.00286049\n",
      "0.0028593652\n",
      "0.0028582762\n",
      "0.002857219\n",
      "0.0028561933\n",
      "0.002855196\n",
      "0.0028542262\n",
      "0.0028532813\n",
      "0.0028523607\n",
      "0.0028514625\n",
      "0.0028505852\n",
      "0.0028497267\n",
      "0.0028488874\n",
      "0.0028480655\n",
      "0.0028472643\n",
      "0.0028464806\n",
      "0.0028457127\n",
      "0.0028449586\n",
      "0.0028442175\n",
      "0.0028434894\n",
      "0.002842773\n",
      "0.0028420675\n",
      "0.002841373\n",
      "0.002840687\n",
      "0.0028399802\n",
      "0.002839284\n",
      "0.0028386007\n",
      "0.0028379278\n",
      "0.0028373108\n",
      "0.0028367063\n",
      "0.0028361117\n",
      "0.002835528\n",
      "0.002834954\n",
      "0.0028343902\n",
      "0.0028338355\n",
      "0.00283329\n",
      "0.002832752\n",
      "0.0028322232\n",
      "0.0028317007\n",
      "0.0028311862\n",
      "0.0028306795\n",
      "0.002830178\n",
      "0.0028296825\n",
      "0.0028291936\n",
      "0.00282871\n",
      "0.0028282325\n",
      "0.0028277603\n",
      "0.002827292\n",
      "0.0028268278\n",
      "0.0028263663\n",
      "0.0028259114\n",
      "0.00282546\n",
      "0.0028250115\n",
      "0.0028245673\n",
      "0.0028241263\n",
      "0.0028236886\n",
      "0.0028232532\n",
      "0.002822821\n",
      "0.0028223924\n",
      "0.0028219644\n",
      "0.0028215405\n",
      "0.0028211188\n",
      "0.0028206997\n",
      "0.002820281\n",
      "0.0028198664\n",
      "0.0028194517\n",
      "0.0028190403\n",
      "0.0028186305\n",
      "0.0028182212\n",
      "0.0028178142\n",
      "0.0028174089\n",
      "0.0028170038\n",
      "0.0028166012\n",
      "0.0028161984\n",
      "0.0028157982\n",
      "0.0028153984\n",
      "0.002814999\n",
      "0.0028146012\n",
      "0.0028142042\n",
      "0.0028138084\n",
      "0.0028134119\n",
      "0.0028130175\n",
      "0.0028126233\n",
      "0.0028122305\n",
      "0.0028118372\n",
      "0.0028114438\n",
      "0.0028110507\n",
      "0.0028106598\n",
      "0.002810267\n",
      "0.0028098756\n",
      "0.0028094843\n",
      "0.002809093\n",
      "0.0028087017\n",
      "0.0028083103\n",
      "0.0028079199\n",
      "0.0028075278\n",
      "0.002807137\n",
      "0.0028067466\n",
      "0.002806355\n",
      "0.002805965\n",
      "0.0028055736\n",
      "0.0028051808\n",
      "0.0028047895\n",
      "0.002804397\n",
      "0.0028040046\n",
      "0.0028036123\n",
      "0.0028032192\n",
      "0.002802825\n",
      "0.0028024323\n",
      "0.0028020393\n",
      "0.0028016458\n",
      "0.0028012518\n",
      "0.0028008574\n",
      "0.0028004637\n",
      "0.0028000693\n",
      "0.0027996746\n",
      "0.0027992798\n",
      "0.0027988846\n",
      "0.002798489\n",
      "0.0027980944\n",
      "0.0027976981\n",
      "0.002797302\n"
     ]
    }
   ],
   "source": [
    "#数据可视化\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "\n",
    "#这就是我们构建的一层神经网络，并返回这层神经网络的值\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs,Weights)+biases\n",
    "    \n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs          #这个输入层的是输出返回值是outputs\n",
    " \n",
    "#生成一些真实的数据，利用numpy\n",
    "x_data = np.linspace(-1,1,300)[:,np.newaxis]  #后面的中括号就是相当于加上他的维度，  意思就是一个特征有300个例子\n",
    "noise = np.random.normal(0,0.05,x_data.shape)   #利用numpy生成呈正态分布的误差，依次输入，均值，标准差，维度\n",
    "y_data = np.square(x_data)-0.5+noise            #需要拟合的曲线就是  x平方-0.5\n",
    "\n",
    "\n",
    "#定义placeholder为把数据传入神经网络做准备   这是不是相当于神经网络的第一层呢？？？\n",
    "xs = tf.placeholder(tf.float32,[None,1])   #这里的None是代表你输入多少个sample过来都可以，没有规定的意思\n",
    "ys = tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "#添加隐藏层          这一层的返回值是 l1 ，作为下一层的输入\n",
    "l1 = add_layer(xs,1,10,activation_function=tf.nn.relu)  #其实添加层的参数设置就是  \n",
    "                                                        #指出输入的数据，输入的维数，输出的维数，激励函数的指定\n",
    "\n",
    "#添加输出层         这一层的返回值是prediction \n",
    "prediction = add_layer(l1,10,1,activation_function=None)\n",
    "\n",
    "#构建代价函数，\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)  #括号中的0.1就是α学习率。andrew课堂中的\n",
    "                                                            #这个优化器的作用就是 使loss最小化，所以就是minimize\n",
    "\n",
    "\n",
    "#⭐⭐最最最重要的一步就是给全局的变量都要进行初始化\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#绘制出实体的数据,这一段就是绘制出你所提供的数据的散点图\n",
    "\n",
    "fig = plt.figure( )  #这就是先生成一个图片框\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data,y_data)  #通过x_data与y_data来确定散点\n",
    "plt.ion()       #这一行的意思是   打开交互模式,可以连续输入多条线\n",
    "plt.ioff()\n",
    "plt.show()      #显示这张图片\n",
    "\n",
    "\n",
    "#开始进行训练\n",
    "for i in range(10000):                #从0到999的循环\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})       #这一步就是开始训练的\n",
    "    if i % 50 == 0:            #每50次输出一次结果，查看训练效果     \n",
    "        try:\n",
    "            plt.pause(0.5)\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        try:                             #下面的步骤是为了显示整个训练过程中的可视化结果\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction,feed_dict={xs:x_data})\n",
    "        #画出整个的预测\n",
    "        lines = ax.plot(x_data,prediction_value,'r-',lw=5)\n",
    "        plt.pause(0.1)\n",
    "        print(sess.run(loss,feed_dict={xs:x_data,ys:y_data})) #只有里面有用到placeholder的地方，都要用回feed_dict才行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#添加神经层\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    biases = tf.Variable(tf.zeros(1,out_size)+0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs,Weights)+biases\n",
    "    \n",
    "    if "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
